// -*- coding: utf-8 -*-
:encoding: UTF-8

New Distribution Whitepaper
==========================
:Author: Lars Hagström, Anders Widén and Joel Ottosson
7 Jan 2013

== Preface
The purpose of this document is to describe the new distribution mechanism of Safir SDK Core and the related changes. It contains information on the benefits, the requirements and the design.

== Benefits
Robust communication::
  Exclusion of misbehaving nodes;;
    New implementation will have an algorithm that will automatically exclude a node that does not behave properly.
  Slow node will not slow down all nodes;;
    Current implementation means that one node that is "slow", either temporarily or always, will slow down distribution to all other nodes.
  Support for other topologies;;
    A number of issues with the current implementation will be addressed:
    - Is really designed and optimized for LAN with TTL=1. It has been made to work with higher TTL. 
    - Has no support for topologies where all nodes cannot see all other nodes.
    - Does not detect situations where firewalls make communication become "one-way".
Removal of general "join" will simplify design::
  The attempt to add general "join" functionality added a lot of complexity that is very unpredictable and hard to explain/document. Removing the general join will simplify the software.

Addition of specific "join" cases will allow more uses::
  Instead of a general join we want to add two kinds of specific join, which will allow nodes to be reconnected if  a network connection is broken. These kinds of nodes will not support having redundant entities:
  Disconnected node will keep all entities owned on other nodes as read only;;
    An operator console with this setting will still be able to display the "last known" state of all entities. No modification will be allowed and no requests will be served.
  Disconnected node will become empty;;
    An operator console with this setting will still become "empty", i.e. all non-local entities will be deleted (this is the current behavior). When the node is reconnected it will receive all remote entities again. 

Less static configuration::
  We want to provide a "dhcp"-like functionality for configuring nodes, so that instead of configuring the node identities and other details that should be internal you specify a node type, e.g. "operator console" or "Database server", and from that we internally work out what node id a node should have. This would make adding new nodes a lot easier.

Easier to display system status::
  The System Picture functionality will be able to provide a unified picture of the system topology, both for use by the system itself to make sure the system remains robust, but this information can also be displayed to allow users and developers to understand what the system status is.

Simpler to start system::
  Less needs for start scripts. All parts of Safir SDK Core and the rest of the system gets started by the same mechanism.

== 3rd party dependencies
Preferrably some 3rd party products should be used in the development of the new distribution mechanism, to simplify and speed up the development process, and to reduce maintenance costs.

Some requirements:

Platform independence of 3rd party dependencies::
  Chosen technologies shall run on Win32 and Linux.
License::
  Chosen technologies shall have a GPL compatible license, since Safir SDK Core license is GPLv3. See http://www.gnu.org/licenses/license-list.html for the GNU project list of compatible licenses.
Real-Time Behaviour::
  Chosen technologies shall not prevent the Safir SDK Core from having bounded latency.

=== Distribution mechanisms

DDS - http://en.wikipedia.org/wiki/Data_Distribution_Service::
  There are several DDS implementations, both commercial and Open Source. DDS is a large-scale distribution framework in itself, making it an inappropriate choice as an low level distribution mechanism for Safir. What could be of interest is the low-level parts in DDS that are used for basic massage distribution, but such mechanisms are not available as stand-alone products.

[[PGM]]
Pragmatic General Multicast - http://en.wikipedia.org/wiki/Pragmatic_General_Multicast::
  PGM is a reliable multicast transport protocol that guarantees an ordered sequece of packets without gaps to multiple 
  recipients simultaneously.  PGM is a NAK protocol which means that a receiver will send a unicast NAK to the sender whenever it detects loss of 
  data. Repair data will be sent to recover from data loss if it is possible. The protocol also detects if a receiver has ended up in an 
  unrecoverable state.

[[OpenPGM]]
OpenPGM - http://code.google.com/p/openpgm::
  A well-known open source implementation of <<PGM, PGM>> specification. It supports most big platforms such as Windows and Linux and also has a beta version for Android.
  
ZeroMQ - http://www.zeromq.org::
  An open source (LGPL) library that offers lightweight message based socket-like communication. It offers different kind of services where publish-subscribe 
  and peer-to-peer seems to be most interesting for us. It handles message fragmentation and always delivers complete   
  messages no matter what underlying transport protocol being used. ZeroMQ supports Tcp and UDP multicast using <<OpenPGM, OpenPGM>>. It also supports inter-thread  
  communication and on Linux it even has inter-process communication.
  There is no broker or deamon that needs to run seperately and the main focus is performance and high throughput with minimal locking. It 
  supports many platforms including Windows and Linux and has a quite big community. 

Bittorrent/P2P::
  This is not a technology that we can use directly per se, but we can find useful algorithms and ideas in the enormous amounts of research that has been done in academia in this area.

The Spread Toolkit - http://www.spread.org/::
  General message bus, with both singlecast and multicast with and without delivery and ordering guarantees. Requires one or several server processes to be executing. The open source license includes the following GPL incompatible "advertising clause", which prohibits us from selecting this toolkit while maintaining the license of Safir SDK Core:

  All advertising materials (including web pages) mentioning features or use of 
  this software, or software that uses this software, must display the following 
  acknowledgment: "This product uses software developed by Spread Concepts LLC 
  for use in the Spread toolkit. For more information about Spread see 
  http://www.spread.org"

Database replication mechanisms::
  widde

[[AMQP]]
Advanced Message Queuing Protocol (AMQP) - http://www.amqp.org/about/what::
  AMQP is an open standard for business message passing. The protocol relies on a central broker that all messages must pass through.
  The central boker adds latency and effects the performance negative. Also scalability will suffer from the central broker design.

[[RabbitMQ]]
RabbitMQ - http://www.rabbitmq.com::  
  Along with <<Qpid, Apache Qpid>>, RabbitMQ is one of the major implementations of <<AMQP, AMQP>>.
  
[[Qpid]]
Apache Qpid - http://qpid.apache.org::
  Along with <<RabbitMQ, RabbitMQ>>, Apache Qpid is one of the major implementations of <<AMQP, AMQP>>.

[[MassTransit]]
MassTransit - http://masstransit-project.com/::
  From the web site: ++MassTransit (MT) is a framework for creating distributed applications on the .Net platform. MT provides the ability to subscribe to messages by type and then connect different processing nodes though message subscriptions building a cohesive mesh of services.++ Introducing a dependency to a .Net framework from the core parts of the dob, that is implemented in C++, is not what we want. Also, although the framework has some support for Mono, this
  is not a natural choice when we have multiplatform requirements.   

NServiceBus - http://www.nservicebus.com/::
  From the web site: ++Developer-friendly SOA for .Net++
  This is not useful for Safir. See <<MassTransit, MassTransit>> 

==== Conclusion
We think that *ZeroMQ* will be a good choice to build the new communication mechanism on. The LGPL license, the small footprint as well as the message fragmentation handling in conjunction with the publish-subscribe pattern seems appealing, especially when using PGM as transport protocol since a multicast protocol with NAK is very suited to our needs. The API concepts of ZeroMQ are very well suited to our needs, and will not change any of our internal communication concepts or affect our external interfaces.

There is quite a bit of functionality that we need to implement on top of ZeroMQ, such as providing a common picture of the system topology, and providing robustness when a node does not keep up with the pace of the rest of the system. ZeroMQ on its own will just discard messages when a peer does not respond. ZeroMQ does not support singlecast over UDP which means that if a singlecast mechanism is needed we have to implement it ourselves or we can decide that it's fine to send addressed data as multicast.

=== Data format / Serialization
Using an open or standard format for the data packets and data headers would remove the need of "rolling our own", and probably also easier to use third party tools such as Wireshark for debugging.

We want a binary format since the blobs are already binary, so XML- or JSON-based formats have not been investigated.

In some distant future we might also want to change the blob format to use an open format, but in the short term we will just wrap them in whatever format we choose.

We only need support for C\+\+, since all the data transport and blob packing/unpacking code is C++ code.

Protobuf - http://code.google.com/p/protobuf/::
  * Google developed data serialization format. 
  * Used by almost all Google internal RPC and file formats. 
  * Well documented and well supported (by Google).
  * There are also multiple implementations, e.g. SAX-like deserialization libraries are available.
  * Stable and widely used.
  * BSD 3-Clause License (GPL compatible)
Apache Thrift - http://thrift.apache.org/::
  * Interfaces to more languages than Protobuf.
  * Slightly larger serialized results compared to Protobuf.
  * Maintenance seems less "professional" than Protobuf.
  * Apache License 2.0 (GPLv3 compatible)

==== Conclusion
*Protobuf* seems to be the sensible choice. Wider usage, better documentation and better maintenance/development.

== Requirements

TODO: Write about new and existing requirements.

== Design
This section describes the design of the new distribution mechanism and the related changes to Safir SDK Core.

=== Overview

In the design for the new communication mechanism we have strived to layer the functionality as much as possible. <<block-diagram, Below>> is a layer diagram that shows the new parts (highlighted) of Safir SDK Core.

[[block-diagram]]
.Block diagram ("new" parts highlighted)
image::block-diagram.png["Block Diagram", width=232, link="block-diagram.png"]

The responsibilities of the new parts can be summarized as follows:

Communication::
  - Provides the low level node to node communication.
  - Discovery of new nodes.
  - Filters received data, to ensure that only data from nodes that are part of the system is handled.
  - Abstracts addressing, so that other parts of the system does not have to worry about IP addresses and port numbers.

System Picture::
  - Decides which nodes are allowed to be part of the system.
  - Data routing decisions
  - Sync between nodes.

Control LowLevel::
  - Starts Safir SDK Core (dose_main, dope_main etc)
  - Starts user applications
  - Decides when/if Dobs on different nodes are allowed to communicate.

Control HighLevel::
  - Provides Dob objects of the application and group statuses of Control LowLevel.
  - Allows control of applications and groups through the Dob objects.

=== Control - Application Start/Stop

This component will be based on the existing Snac component, with a few notable changes:

 * New name will be "Safir Control" ("Control" will be used in this document, for short), to reflect the fact that this "new" component is somehow in control of the whole system. The user will start safir_control(.exe) which in turn starts dose_main and dope_main and then starts all the other applications. Starting safir_control is a bit less cryptic than starting a lot of xxxx_main applications.
 * Dependencies to ACE will be removed
 * Dependencies to non-Core parts of Safir SDK will be removed
 * Since we want Control to start the Dob it will use the new communication mechanism directly, instead of using the Dob.
 * Will have a low level part and a high level part.
   - The low level part does most of the work, but does 'not' depend on Dose or Dots. This means that low level part will not have the Dob shared memories loaded, and can not be affected by a corrupt shared memory. 
   - The high level part provides dob objects that behave the same way that the current Snac objects do.
 * Current Master and Slave concepts will most likely be kept.

A first iteration of Control will probably just launch Safir SDK Core and then launch the existing Snac.

TODO: should we use Boost.Process, not yet part of Boost. http://www.highscore.de/boost/process0.5/

=== System Picture

To be able to provide a system picture ('SP' for short) the System Picture component has to collect communication statistics from Communication. This data consists of timing information and packet loss information, etc. This low level information ('RAW' for short) is collected on all nodes, and distributed to all other nodes. 

From this RAW data System Picture has to produce an SP, that is identical on all nodes. Either this can be done on one node (a 'master' node), or on each node using an algorithm that is guaranteed to produce identical output on all nodes.

An advantage of having the RAW and SP data available on all nodes is that it will be possible to view all of this data on each node (e.g. in dobexplorer), instead of having to check on each node.

==== Transportation of SP and RAW within a node
Since Control, dose_main and dobexplorer are separate executables the SP and RAW data has to be transported between them. This will be achieved using local ZeroMQ PUB/SUB sockets, to avoid use of shared memory or platform specific IPC.

So the System Picture in dose_main will publish its RAW data, and the System Picture in Control will publish its RAW and SP data.

[[sp-raw-pub-sub]]
.System Picture data
image::sp_raw_pub_sub.png["System Picture Pub/Sub", width=401, link="sp_raw_pub_sub.png"]

All of these ZeroMQ sockets will use TCP/IP communication over the loopback interface (127.0.0.1), to make sure that it is computer-local.

=== Communication
Communication's main responsibilities are to detect new nodes and send and receive messages to/from other nodes. Whenever a new node is detected Communication will report it to System Picture who decides which nodes are part of the system. Communication shall filter incoming messages and only deliver messages received from other system nodes.

Only complete messages shall be delivered, and messages shall be delivered in correct order, i.e the order they were sent. Actually these requirements are already handled by ZeroMQ. Communication must also be able to detect when a message is lost and report it as a failure.

==== Protocol
ZeroMQ and the http://zguide.zeromq.org/page:all#Chapter-Advanced-Publish-Subscribe-Patterns[publish-subscribe] pattern will be used for all the low-level communication. Each node will have at least one publisher socket and one subscriber socket, and supported transport protocols are tcp and epgm which is pgm multicast on top of udp.

To avoid unnecessary copying, message headers and message data will be separated using ZeroMQ's multipart messages. That makes it possible to write the data part in shared memory immediately without any intermediate storage.

==== Node types
We introduce a new concept called node type. It shall be possible to define node types with a number of common parameters and then tag every node with a node type. For example one node type could be RT_NODE and another IS_NODE. A node tagged as RT_NODE might have a higher minimum receive data rate than a node tagged as IS_NODE. The node type affects how data are sent to the node and the requirements that must be met to be part of the system.

==== Distribution channels
Each distribution channel will have a pair of multicast sockets per node type. In such pair, one socket is flow controlled (FC for short) and one is not flow controlled (NFC for short).

On an NFC socket the sender is allowed to send as fast as it wants and a receiver is allowed to drop messages if it can't keep up with the pace. Still, if using PGM as transport protocol, NAKs and Data is sent as usual, so a lost message will only occur in case of PGM unrecoverable data loss. NFC sockets will probably have shorter PGM recovery interval, to reduce memory use, so PGM unrecoverable data losses may not be uncommon when data flow is high.

An FC socket on the other hand has a minimum transfer rate, defined by the node type, that a receiver must obey. If a receiver starts to send NAK's the sender shall slow down the pace, but if the receiver continues to NAK messages when the send rate has dropped to the minimum level, the receiver may be excluded from the system. The exact criteria for node exclusion have not been decided yet.

It may be possible to just have one PGM NFC socket for all node types per distribution channel. PGM recovery interval settings may influence this choice.

==== Questions
One question that needs more investigation is how big the benefits are of using ZeroMQ's multicast over using OpenPGM directly. ZeroMQ is an additional layer on top of OpenPGM with an interface that looks a bit easier to use. On the downside the simplification means that some features and parameters available in OpenPGM are hidden by ZeroMQ and not easily available to users. ZeroMQ handles message fragmentation which is really nice to have out of the box, however OpenPGM also claims to handle some kind of message fragmentation.

We would also like to use ZeroMQs TCP socket implementation for communication with nodes that are not reachable by UDP multicast.

== Use cases
The DOB supports three kinds of mechanism: entities, messages and requests (service requests and entity requests). Here we try to show how each of these are realized on the proposed design.

=== Messages
In the current Dob implementation there are no guarantees that messages are delivered to all subscribers, but if a message is sent on an acked priority level the Dob guarantees that the message will arrive to the node. But after the message has arrived to the node there are no guarantees that it is delivered to all subscribers.

If we choose to use a NAK-protocol such as PGM, there are two possible ways to send messages:

 * Send as NFC - messages will still have no guarantees to be delivered and a slow node will never be excluded because of messages. There is a small difference from the implementation of today; there are no longer any guarantees that a message will reach the node at all.
 * Send as flow controlled - messages will still have no guarantees to be delivered. Contrary to sending on NFC sockets it is now guaranteed that all messages will reach the receiver nodes, and a receiving node that is too slow will be excluded from the system.

TODO: We should have a proposal for messages with some kind of guarantees in this iteration.

=== Entities
Entities can be sent on FC or NFC sockets depending on type, just like they are sent acked or unacked in the current implementation.

=== Requests
TODO med multicast eller med egen udp?

